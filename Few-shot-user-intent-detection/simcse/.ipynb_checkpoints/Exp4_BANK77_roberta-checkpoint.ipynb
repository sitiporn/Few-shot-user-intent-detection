{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4273c4c0-7a0d-4f65-ac85-94eab3d96acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaConfig, RobertaModel, RobertaTokenizer, RobertaForSequenceClassification\n",
    "from transformers import AdamW\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from scipy.spatial.distance import cosine\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'simcse')))\n",
    "from sim_utils import load_examples, Inputexample, CustomTextDataset, freeze_layers, test, train    \n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, AutoConfig, AutoModel, AutoTokenizer\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "\n",
    "#comment this if you are not using puffer\n",
    "os.environ['http_proxy'] = 'http://192.41.170.23:3128'\n",
    "os.environ['https_proxy'] = 'http://192.41.170.23:3128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc6c51d5-d0c7-4f33-ab80-f162dd62d394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May  2 04:46:57 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:84:00.0 Off |                  N/A |\n",
      "| 24%   28C    P8    12W / 250W |      1MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  On   | 00000000:85:00.0 Off |                  N/A |\n",
      "| 22%   29C    P8     1W / 250W |      1MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  On   | 00000000:88:00.0 Off |                  N/A |\n",
      "| 22%   27C    P8     6W / 250W |      1MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  On   | 00000000:89:00.0 Off |                  N/A |\n",
      "| 22%   27C    P8     4W / 250W |      1MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "054552b4-61ec-4802-a4cf-940399618865",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "\n",
    "\n",
    "train_samples = []\n",
    "train_labels = []\n",
    "\n",
    "valid_samples = []\n",
    "valid_labels = []\n",
    "\n",
    "test_samples = []\n",
    "test_labels = []\n",
    "\n",
    "embed_dim = 768\n",
    "batch_size = 16 \n",
    "lr=2e-3  # you can adjust \n",
    "temp = 0.3  # you can adjust \n",
    "lamda = 0.01  # you can adjust  \n",
    "skip_time = 0 # the number of time that yi not equal to yj in supervised contrastive loss equation \n",
    "\n",
    "device = 'cpu'\n",
    "# torch.device('cuda:3' if torch.cuda.is_available() else 'cpu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f74f4d44-1683-4d21-a12e-7500f0dbc621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== test set ====\n",
      "Train on Cross Entropy loss\n",
      "len of dataset : 3080\n"
     ]
    }
   ],
   "source": [
    "#['CLINC150','BANKING77','HWU64'] \n",
    "test_path = f'../../../BANKING77/test/'\n",
    "\n",
    "# load data\n",
    "test_samples = load_examples(test_path)\n",
    "\n",
    "\n",
    "print(\"===== test set ====\")\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(len(test_samples)):\n",
    "    data.append(test_samples[i].text)\n",
    "    labels.append(test_samples[i].label)\n",
    "\n",
    "test_data = CustomTextDataset(labels,data,batch_size=batch_size,repeated_label=False)\n",
    "test_loader = DataLoader(test_data,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    " # got the number of unique classes from dataset\n",
    "num_class = len(np.unique(np.array(labels)))\n",
    "\n",
    " # get text label of uniqure classes\n",
    "unique_label = np.unique(np.array(labels))\n",
    "\n",
    " # map text label to index classes\n",
    "label_maps = {unique_label[i]: i for i in range(len(unique_label))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34bfd389-99fb-476e-bb95-67c2ecd9e692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/unsup-simcse-bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"princeton-nlp/unsup-simcse-bert-base-uncased\")\n",
    "config = AutoConfig.from_pretrained(\"princeton-nlp/unsup-simcse-bert-base-uncased\")\n",
    "config.num_labels = num_class\n",
    "config.output_hidden_states = True\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"princeton-nlp/unsup-simcse-bert-base-uncased\",config=config)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae95bfaf-9a6c-41de-8f66-465f3f4b5920",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_list = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b66176d8-963c-42be-89b3-3b980500b262",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (idx, batch) in enumerate(test_loader):\n",
    "        sentence = batch[\"Text\"]\n",
    "        inputs = tokenizer(sentence,padding=True,truncation=True,return_tensors=\"pt\")\n",
    "\n",
    "        # move parameter to device\n",
    "        inputs = {k:v.to(device) for k,v in inputs.items()}\n",
    "\n",
    "        # map string labels to class idex\n",
    "        labels = [label_maps[stringtoId] for stringtoId in (batch['Class'])]\n",
    "        \n",
    "        # convert list to tensor\n",
    "        labels = torch.tensor(labels).unsqueeze(0)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        \n",
    "        # Foward pass \n",
    "        outputs = model(**inputs,labels=labels)\n",
    "        \n",
    "        embeddings = outputs.hidden_states[-1]\n",
    "        \n",
    "        #select first token \n",
    "        embeddings = embeddings[:,0,:]\n",
    "        \n",
    "        embed_list.append(embeddings)\n",
    "        y.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f74a555-9dc9-4b1f-8ab7-be2980e472f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_list = torch.cat(y,axis=1)\n",
    "\n",
    "y_list = torch.squeeze(y_list,dim=0)\n",
    "\n",
    "y_list = y_list.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "024ec554-af5b-4070-8814-c815f7ce4b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3080"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82ac24a9-e147-4c37-870c-ec924192e1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:819: FutureWarning: 'square_distances' has been introduced in 0.24 to help phase out legacy squaring behavior. The 'legacy' setting will be removed in 1.1 (renaming of 0.26), and the default setting will be changed to True. In 1.3, 'square_distances' will be removed altogether, and distances will be squared by default. Set 'square_distances'=True to silence this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "res = torch.cat(embed_list, axis=0)\n",
    "# Instantialte tsne, specify cosine metric\n",
    "tsne = TSNE(random_state = 0, n_iter = 3000, metric = 'cosine')\n",
    "# Fit and transform\n",
    "embeddings2d = tsne.fit_transform(res.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeba70b9-8eb4-4e4f-a4e3-a5c81552cb95",
   "metadata": {
    "tags": []
   },
   "source": [
    "##  Low dimensional Embedding vectors output from SimCSE : Simple Contrastive Sentence Embeddings Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a738379-93fc-45bb-b972-fbaeab29cdb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize=(45,25))\n",
    "sns.scatterplot(x=embeddings2d[:,0], y=embeddings2d[:,1], hue=y_list,palette=sns.color_palette(\"hls\", 77))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82fcb0e-87d1-42fb-8539-051cc45bd479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602f84bf-0fcf-4819-ba3b-e0d79d945076",
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868b6879-3134-4329-bc3e-b44e276edbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "config.num_labels = num_class\n",
    "config.output_hidden_states = True\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,config=config)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fbb3be-fdbb-4df5-aff7-619cf37645d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_list = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4073be0-373d-41d8-a450-08122cd1ee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (idx, batch) in enumerate(test_loader):\n",
    "        sentence = batch[\"Text\"]\n",
    "        inputs = tokenizer(sentence,padding=True,truncation=True,return_tensors=\"pt\")\n",
    "\n",
    "        # move parameter to device\n",
    "        inputs = {k:v.to(device) for k,v in inputs.items()}\n",
    "\n",
    "        # map string labels to class idex\n",
    "        labels = [label_maps[stringtoId] for stringtoId in (batch['Class'])]\n",
    "        \n",
    "        # convert list to tensor\n",
    "        labels = torch.tensor(labels).unsqueeze(0)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        \n",
    "        # Foward pass \n",
    "        outputs = model(**inputs,labels=labels)\n",
    "        \n",
    "        embeddings = outputs.hidden_states[-1]\n",
    "        \n",
    "        #select first token \n",
    "        embeddings = embeddings[:,0,:]\n",
    "        \n",
    "        embed_list.append(embeddings)\n",
    "        y.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba72c481-6ccf-43a8-9696-2e702a6597f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_list = torch.cat(y,axis=1)\n",
    "\n",
    "y_list = torch.squeeze(y_list,dim=0)\n",
    "\n",
    "y_list = y_list.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f29c26-0be7-4830-a075-e21516645864",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11d1013-6615-4a42-b107-04591c6796a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = torch.cat(embed_list, axis=0)\n",
    "# Instantialte tsne, specify cosine metric\n",
    "tsne = TSNE(random_state = 0, n_iter = 3000, metric = 'cosine')\n",
    "# Fit and transform\n",
    "embeddings2d = tsne.fit_transform(res.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e663402-444e-4dc6-92d0-d03954df0860",
   "metadata": {
    "tags": []
   },
   "source": [
    "##  Low dimensional Embedding vectors Roberta-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ec8569-d6f6-48ca-9bd1-ba190a724b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(45,25))\n",
    "sns.scatterplot(x=embeddings2d[:,0], y=embeddings2d[:,1], hue=y_list,palette=sns.color_palette(\"hls\", 77))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d6c895-6a96-4414-b689-cb3379981849",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
